
// Mock GPT service for scoring prompts
// In a real implementation, this would call the OpenAI API

export interface GPTResponse {
  score: number;
  feedback: string;
}

export const evaluatePrompt = async (prompt: string, questionText: string): Promise<GPTResponse> => {
  // Simulate API delay
  await new Promise(resolve => setTimeout(resolve, 2000));
  
  // Mock scoring logic - in real app, this would be GPT API call
  const promptLength = prompt.length;
  const hasPoliteWords = /ì•ˆë…•|ë¶€íƒ|ê°ì‚¬|ê³ ë§ˆì›Œ|ì œë°œ|ë„ì™€ì£¼ì„¸ìš”|ë¶€íƒë“œë ¤ìš”|í•´ì£¼ì„¸ìš”|ê°€ëŠ¥í•œì§€|ìˆ˜ ìˆì„ê¹Œìš”/.test(prompt);
  const hasSpecificRequest = prompt.length > 20;
  const hasDangerousContent = /ë¹„ë°€ë²ˆí˜¸|ì£¼ì†Œ|ì „í™”ë²ˆí˜¸|ê°œì¸ì •ë³´|í•´í‚¹|ë°”ì´ëŸ¬ìŠ¤/.test(prompt);
  
  let score = 50; // Base score
  let feedback = '';
  
  // Scoring logic
  if (hasPoliteWords) {
    score += 20;
    feedback += 'ì •ì¤‘í•œ í‘œí˜„ì„ ì‚¬ìš©í•´ì„œ ì¢‹ì•„ìš”! ';
  }
  
  if (hasSpecificRequest) {
    score += 20;
    feedback += 'êµ¬ì²´ì ìœ¼ë¡œ ìš”ì²­í•´ì„œ í›Œë¥­í•´ìš”! ';
  }
  
  if (promptLength > 50) {
    score += 10;
    feedback += 'ì¶©ë¶„íˆ ìì„¸í•˜ê²Œ ì„¤ëª…í–ˆì–´ìš”! ';
  }
  
  if (hasDangerousContent) {
    score -= 30;
    feedback = 'ì•ˆì „í•˜ì§€ ì•Šì€ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”. ';
  }
  
  if (!hasPoliteWords && !hasSpecificRequest) {
    feedback = 'ë” ì •ì¤‘í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ìš”ì²­í•´ë³´ì„¸ìš”! ';
  }
  
  // Ensure score is within bounds
  score = Math.max(0, Math.min(100, score));
  
  // Add encouraging message based on score
  if (score >= 80) {
    feedback += 'ì •ë§ í›Œë¥­í•œ í”„ë¡¬í”„íŠ¸ì˜ˆìš”! ğŸŒŸ';
  } else if (score >= 60) {
    feedback += 'ì¢‹ì€ ì‹œì‘ì´ì—ìš”! ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì¨ë³´ì„¸ìš”. ğŸ˜Š';
  } else {
    feedback += 'ì•ˆì „ ìˆ˜ì¹™ì„ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•´ë³´ì„¸ìš”! ğŸ’ª';
  }
  
  return { score, feedback };
};
